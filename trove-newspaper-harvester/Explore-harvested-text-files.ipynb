{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore harvested text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import fileinput\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from textblob import TextBlob\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "\n",
    "# alt.data_transformers.enable('json')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_harvest():\n",
    "    '''\n",
    "    Get the timestamp of the most recent harvest.\n",
    "    '''\n",
    "    harvests = sorted([d for d in Path('data').iterdir() if d.is_dir() and not d.name.startswith('.')])\n",
    "    try:\n",
    "        harvest = harvests[-1]\n",
    "    except IndexError:\n",
    "        print('No harvests!')\n",
    "        harvest = None\n",
    "    return harvest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs(harvest):\n",
    "    docs_path = get_docs_path(harvest)\n",
    "    for p in docs_path:\n",
    "        yield p.read_text(encoding='utf-8').strip()\n",
    "        \n",
    "def get_docs_path(harvest):\n",
    "    path = Path(f'{harvest}/text')\n",
    "    docs_path = [p for p in sorted(path.glob('*.txt'))]\n",
    "    return docs_path\n",
    "\n",
    "def get_file_names(harvest):\n",
    "    return [p.stem for p in get_docs_path(harvest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvest = get_latest_harvest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', max_features=10000, ngram_range=(1,1))\n",
    "# preprocessor = lambda x: re.sub(r'(\\d[\\d\\.])+', 'NUM', x.lower())\n",
    "X_freq = np.asarray(vectorizer.fit_transform(get_docs(harvest)).todense())\n",
    "df_freq = pd.DataFrame(X_freq, columns=vectorizer.get_feature_names(), index=get_file_names(harvest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq.sum().nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of words you want to show\n",
    "num_words = 20\n",
    "top_words = pd.DataFrame({n: df_freq.T[col].nlargest(num_words).index.tolist() for n, col in enumerate(df_freq.T)}).T\n",
    "top_words.index = get_file_names(harvest)\n",
    "top_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a 'year' column to the dataframe\n",
    "\n",
    "Each file name includes the date on which the article was published. For example, `18601224-13-5696044` was published on 24 December 1860. We can easily extract the year by just slicing the first four characters off the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [int(p[:4]) for p in get_file_names(harvest)]\n",
    "df_freq_years = df_freq.assign(year=years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most frequent words each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top words per year\n",
    "year_groups = df_freq_years.groupby(by='year')\n",
    "year_group_totals = year_groups.sum()\n",
    "df_years = pd.DataFrame({n: year_group_totals.T[col].nlargest(10).index.tolist() for n, col in enumerate(year_group_totals.T)}).T\n",
    "df_years.index = [name for name, _ in year_groups]\n",
    "df_years.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise top ten words per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_chart = alt.vconcat()\n",
    "years = df_years.index.tolist()\n",
    "# Number of columns\n",
    "cols = 4\n",
    "start = 0\n",
    "while start < len(years):\n",
    "    row = alt.hconcat()\n",
    "    for year in years[start:start+cols]:\n",
    "        df_year_word_count = pd.DataFrame([{'word': w, 'count': year_group_totals.loc[year][w]} for w in df_years.loc[year].tolist()])\n",
    "        chart = alt.Chart(df_year_word_count).mark_bar().encode(\n",
    "            y='word:N',\n",
    "            x='count:Q',\n",
    "        ).properties(width=120, height=120, title=str(year))\n",
    "        row |= chart\n",
    "    compound_chart &= row\n",
    "    start += cols\n",
    "compound_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise word frequencies over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_by_year(df, words):\n",
    "    df_words = pd.DataFrame()\n",
    "    for word in words:\n",
    "        try:\n",
    "            df_word = df.groupby(by='year').sum()[word].to_frame().reset_index().rename({word: 'count'}, axis=1)\n",
    "        except KeyError:\n",
    "            print(f\"'{word}' not found\")\n",
    "        else:\n",
    "            df_word['word'] = word\n",
    "            df_words = df_words.append(df_word, ignore_index=True)\n",
    "    return df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = words_by_year(df_freq_years, ['weather', 'wragge', 'storm', 'chinese', 'kangaroo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a faceted chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_words.loc[df_words['year'] > 0]).mark_line().encode(\n",
    "    x=alt.X('year:Q', axis=alt.Axis(format='c', title='Year')),\n",
    "    y='count:Q',\n",
    "    color='word:N',\n",
    "    facet=alt.Facet('word:N', columns=1)\n",
    ").properties(width=700, height=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a bubbleline chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chart\n",
    "alt.Chart(df_words.loc[df_words['year'] > 0]).mark_circle(\n",
    "    \n",
    "    # Style the circles\n",
    "    opacity=0.8,\n",
    "    stroke='black',\n",
    "    strokeWidth=1\n",
    ").encode(\n",
    "    \n",
    "    # Year on the X axis\n",
    "    x=alt.X('year:O', axis=alt.Axis(format='c', title='Year', labelAngle=0)),\n",
    "    \n",
    "    # Object type on the Y axis\n",
    "    y=alt.Y('word:N', title='Word'),\n",
    "    \n",
    "    # Size of the circles represents the number of objects\n",
    "    size=alt.Size('count:Q',\n",
    "        scale=alt.Scale(range=[0, 2000]),\n",
    "        legend=alt.Legend(title='Frequency')\n",
    "    ),\n",
    "    \n",
    "    # Color the circles by object type\n",
    "    color=alt.Color('word:N', legend=None),\n",
    "    \n",
    "    # More details on hover\n",
    "    tooltip=[alt.Tooltip('word:N', title='Word'), alt.Tooltip('year:O', title='Year'), alt.Tooltip('count:Q', title='Frequency', format=',')]\n",
    ").properties(\n",
    "    width=700,\n",
    "    height=300\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
